Homework 5
================
Paula Wu
11/15/2021

Import the libraries

``` r
library(tidyverse)
```

## Problem 1

This answer is not part of the homework requirement. Just for
self-practice purpose

``` r
# first clean the data set
homicide_df = 
  read_csv("./data/homicide-data.csv", na = c("", "Unknown")) %>%  # account for empty/unknown entries
  mutate(
    city_state = str_c(city, state),
    resolution = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    )) %>% 
  relocate(city_state) %>% 
  filter(city_state != "TulsaAL")
```

First focus on Baltimore, MD

``` r
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "BaltimoreMD")

baltimore_summary = 
  baltimore_df %>% 
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n() 
  )

baltimore_test =
  prop.test(
    x = baltimore_summary %>% pull(unsolved), 
    n = baltimore_summary %>% pull(n))

baltimore_test %>% # for better presentation of the test results
  broom::tidy()
```

    ## # A tibble: 1 × 8
    ##   estimate statistic  p.value parameter conf.low conf.high method    alternative
    ##      <dbl>     <dbl>    <dbl>     <int>    <dbl>     <dbl> <chr>     <chr>      
    ## 1    0.646      239. 6.46e-54         1    0.628     0.663 1-sample… two.sided

Then extend this to the rest of the data set: iterate across cities

``` r
prop_test_function = function(city_df){
  city_summary = 
    city_df %>% 
    summarize(
      unsolved = sum(resolution == "unsolved"),
      n = n())

  city_test =
    prop.test(
      x = city_summary %>% pull(unsolved), 
      n = city_summary %>% pull(n))

  return(city_test)
}
```

``` r
results_df = 
  homicide_df %>% 
  nest(data = uid:resolution) %>% 
  mutate(
    test_results = map(data, prop_test_function),
    tidy_results = map(test_results, broom::tidy)
  ) %>% 
  select(city_state, tidy_results) %>% 
  unnest(tidy_results) %>% 
  select(city_state, estimate, starts_with("conf"))  # get the confidence interval and estimate
```

Make a plot showing estimates and confidence interval

``` r
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

<img src="p8105_hw5_pw2551_files/figure-gfm/unnamed-chunk-6-1.png" width="90%" />
<br> Another way to solve the question using `map2()`, will not evaluate
here for concision purpose

``` r
homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n()
  ) %>% 
  mutate(
    test_results = map2(unsolved, n, prop.test),
    tidy_results = map(test_results, broom::tidy)
  ) %>% 
  select(city_state, tidy_results) %>% 
  unnest(tidy_results) %>% 
  select(city_state, estimate, starts_with("conf"))
```

<br>

## Problem 2

Read in data sets and store in a data frame

``` r
study_df = 
  tibble(file_names = list.files("./data/p2_data", pattern = ".csv")) %>% 
  mutate(path = str_c("./data/p2_data/", file_names),  # create relative paths
         content = map(.x = path, ~read_csv(.x))) %>% 
  separate(file_names, into = c("arms", "subject_id")) %>% 
  mutate(arms = as.factor(recode(arms, "con" = "control", "exp" = "experiment"))) %>% 
  select(-path) %>% 
  unnest(content)
knitr::kable(study_df[1:5,])  # choose to display first five lines on purpose
```

| arms    | subject_id | week_1 | week_2 | week_3 | week_4 | week_5 | week_6 | week_7 | week_8 |
|:--------|:-----------|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-------:|
| control | 01         |   0.20 |  -1.31 |   0.66 |   1.96 |   0.23 |   1.09 |   0.05 |   1.94 |
| control | 02         |   1.13 |  -0.88 |   1.07 |   0.17 |  -0.83 |  -0.31 |   1.58 |   0.44 |
| control | 03         |   1.77 |   3.11 |   2.22 |   3.26 |   3.31 |   0.89 |   1.88 |   1.01 |
| control | 04         |   1.04 |   3.66 |   1.22 |   2.33 |   1.47 |   2.70 |   1.87 |   1.66 |
| control | 05         |   0.47 |  -0.58 |  -0.09 |  -1.37 |  -0.32 |  -2.17 |   0.45 |   0.48 |

<br>Make a spaghetti plot

``` r
study_df %>% 
  pivot_longer(week_1:week_8, 
               names_to = "weeks", 
               names_prefix = "week_", 
               values_to = "observations") %>% 
  mutate(weeks = as.numeric(weeks),
         subjects = str_c(recode(arms, "control" = "con", "experiment" = "exp"), " _ ", subject_id)) %>% 
  ggplot(aes(x = weeks, y = observations, group = subjects)) +
  geom_line(aes(color = subjects)) +
  ggtitle("Observation of Subjects by Group") +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(x = "Weeks", y = "Observed Value") +
  facet_grid(.~arms)
```

<img src="p8105_hw5_pw2551_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />
<br> As we can see from the above spaghetti plot, subjects in both
groups have similar observed values (observations) in general. As time
goes by, the experiment group shows a clear positive trend. On the
contrary, the overall trend in the control group is nearly horizontal.
Thus, the experiment group has greater observed values than control
group did. <br>

## Problem 3

Get the dataset

``` r
set.seed(10)
iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species)) %>% 
  janitor::clean_names()  # just to tidy things up
```

Write the function to address problems

``` r
iris_impute = function(col_vec){
  if(is.character(col_vec)){
    col_vec = replace_na(col_vec, "virginica")
  }else if(is.numeric(col_vec)){
    vec_mean = mean(col_vec, na.rm = TRUE)
    col_vec = replace_na(col_vec, vec_mean)
  }
  return(col_vec)
}
```

Applied the function to the iris_with_missing dataset

``` r
iris_filled = 
  map(iris_with_missing, iris_impute) %>% 
  as_tibble() 
```

Header of the imputed data set

``` r
knitr::kable(iris_filled[1:10,], digits = 2)
```

| sepal_length | sepal_width | petal_length | petal_width | species |
|-------------:|------------:|-------------:|------------:|:--------|
|         5.10 |         3.5 |         1.40 |        0.20 | setosa  |
|         4.90 |         3.0 |         1.40 |        0.20 | setosa  |
|         4.70 |         3.2 |         1.30 |        0.20 | setosa  |
|         4.60 |         3.1 |         1.50 |        1.19 | setosa  |
|         5.00 |         3.6 |         1.40 |        0.20 | setosa  |
|         5.40 |         3.9 |         1.70 |        0.40 | setosa  |
|         5.82 |         3.4 |         1.40 |        0.30 | setosa  |
|         5.00 |         3.4 |         1.50 |        0.20 | setosa  |
|         4.40 |         2.9 |         1.40 |        0.20 | setosa  |
|         4.90 |         3.1 |         3.77 |        0.10 | setosa  |

<br>Finally, I generate a table that counts NA values of the
`iris_filled` dataset to demonstrate the efficacy of the `iris_impute()`
function

``` r
iris_filled %>% 
  select(everything()) %>%  
  summarise_all(funs(sum(is.na(.)))) %>% 
  knitr::kable()
```

| sepal_length | sepal_width | petal_length | petal_width | species |
|-------------:|------------:|-------------:|------------:|--------:|
|            0 |           0 |            0 |           0 |       0 |

Results above show the completeness of the data set after applying the
`iris_impute()` function to `iris_with_missing` data set.
